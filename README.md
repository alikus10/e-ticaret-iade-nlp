
# ğŸ›ï¸ E-Ticaret Ä°ade GerekÃ§esi Benzerlik SÄ±nÄ±flandÄ±rmasÄ±

Bu proje, e-ticaret platformlarÄ±ndaki iade nedenlerini doÄŸal dil iÅŸleme (NLP) teknikleri ile analiz ederek benzer gerekÃ§eleri sÄ±nÄ±flandÄ±rmayÄ± amaÃ§lar. Proje, `ecommerce_returns_synthetic_data.csv` adlÄ± sentetik veri seti Ã¼zerinde yÃ¼rÃ¼tÃ¼lmÃ¼ÅŸtÃ¼r.

## ğŸ” AmaÃ§
- Ä°ade gerekÃ§elerini metinsel olarak analiz etmek
- TemizlenmiÅŸ veriler Ã¼zerinde TF-IDF ve Word2Vec yÃ¶ntemlerini uygulamak
- AnlamlÄ± kelime benzerlikleri ve sÄ±nÄ±flandÄ±rma potansiyeli ortaya koymak

## ğŸ“ KlasÃ¶r YapÄ±sÄ±

```
ecommerce-returns-nlp/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ecommerce_returns_synthetic_data.csv
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ lemmatized_sentences.csv
â”‚   â”œâ”€â”€ stemmed_sentences.csv
â”‚   â”œâ”€â”€ tfidf_lemmatized.csv
â”‚   â”œâ”€â”€ tfidf_stemmed.csv
â”‚   â””â”€â”€ word2vec_models/
â”‚       â”œâ”€â”€ word2vec_lemmatized_cbow_win2_dim100.model
â”‚       â”œâ”€â”€ ...
â”œâ”€â”€ preprocessing.py
â”œâ”€â”€ tfidf_vectorize.py
â”œâ”€â”€ word2vec_train.py
â”œâ”€â”€ word2vec_model_test.py
â””â”€â”€ README.md
```

## ğŸ§¼ Ã–n Ä°ÅŸleme AÅŸamalarÄ±

- KÃ¼Ã§Ã¼k harfe Ã§evirme
- Noktalama ve Ã¶zel karakter temizliÄŸi
- Stopword Ã§Ä±karÄ±mÄ± (NLTK)
- Lemmatization (spaCy)
- Stemming (PorterStemmer)

Ã‡Ä±ktÄ±lar:
- `lemmatized_sentences.csv`
- `stemmed_sentences.csv`

## ğŸ“Š Zipf YasasÄ± Analizi

Her veri seti iÃ§in log-log Zipf grafiÄŸi Ã§izilmiÅŸtir:
- `zipf_raw.py` â†’ Ham veri
- `zipf_lemmatized.py` â†’ Lemmatized veri
- `zipf_stemmed.py` â†’ Stemmed veri

Grafikler `matplotlib` kullanÄ±larak gÃ¶rselleÅŸtirilmiÅŸtir.

## ğŸ“ˆ TF-IDF VektÃ¶rleÅŸtirme

- Uygulanan dosyalar: `tfidf_vectorize.py`
- KullanÄ±lan araÃ§: `TfidfVectorizer` (scikit-learn)
- Ã‡Ä±ktÄ±lar:
  - `tfidf_lemmatized.csv`
  - `tfidf_stemmed.csv`

## ğŸ§  Word2Vec Model EÄŸitimi

Gensim kullanÄ±larak toplam **16 Word2Vec modeli** eÄŸitilmiÅŸtir.  
EÄŸitim parametreleri:

```python
parameters = [
  {'model_type': 'cbow', 'window': 2, 'vector_size': 100},
  {'model_type': 'skipgram', 'window': 2, 'vector_size': 100},
  ...
  {'model_type': 'skipgram', 'window': 4, 'vector_size': 300}
]
```

Model isimlendirme:
```
word2vec_lemmatized_cbow_win2_dim100.model
word2vec_stemmed_skipgram_win4_dim300.model
...
```

Her model iÃ§in `"wrong"` gibi anahtar kelimelerle benzer kelimeler analiz edilmiÅŸtir.

## ğŸ§ª Ã–rnek Test: Word2Vec

```python
from gensim.models import Word2Vec
model = Word2Vec.load("output/word2vec_models/word2vec_lemmatized_cbow_win2_dim100.model")
print(model.wv.most_similar("wrong", topn=5))
```

Ã–rnek Ã§Ä±ktÄ±:
```
[('item', 0.91), ('product', 0.89), ('received', 0.87), ('different', 0.85), ('sent', 0.84)]
```

## âš™ï¸ Gereksinimler

```bash
pip install pandas nltk spacy gensim scikit-learn matplotlib
python -m nltk.downloader stopwords
python -m spacy download en_core_web_sm
```

## ğŸ“Œ Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r.
